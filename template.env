# For other LLMs see: https://docs.crewai.com/concepts/llms

##### Ollama settings
MODEL=ollama/granite3.3
API_BASE=http://localhost:11434

#####  watsonx.ai settings.
#WATSONX_URL="https://us-south.ml.cloud.ibm.com"
#WATSONX_API_KEY="...."
#WATSONX_PROJECT_ID="...."
#MODEL="watsonx/ibm/granite-3-3-8b-instruct"

##### Debugging LiteLLM
#LITELLM_LOG=DEBUG

##### Langfuse settings.
## Host URL must end with: /api/public/otel
#LANGFUSE_PUBLIC_KEY=pk-...
#LANGFUSE_SECRET_KEY=sk-...
#LANGFUSE_ID=your_identifier
#LANGFUSE_HOST=https://cloud.langfuse.com/api/public/otel
#OTEL_METRICS_EXPORTER=none
#OTEL_LOGS_EXPORTER=none
